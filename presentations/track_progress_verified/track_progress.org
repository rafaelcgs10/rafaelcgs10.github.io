#+TITLE: Verified Progress Tracking for Timely Dataflow
#+AUTHOR: Rafael Castro
#+EMAIL: rafaelcgs10@gmail.com
#+LANGUAGE: en
#+DATE: 11/09/2021

* What this presentation is about?
** Paper: Verified Progress Tracking for Timely Dataflow by Matthias Brun, SÃ¡ra Decova, Andrea Lattuada, Dmitriy Traytel
** Core concepts and contributions
** Possible next steps
* What is the Timely Dataflow program model?
** It is a programming framework and a model of computation
** A program defined by a graph model: edges (channels) and vertex (operators)
#+ATTR_ORG: :width 600
     [[./dataflow.png]]
*** Channels: move data (messages) between operators
*** Operators: per tuple data transformation
**** Input and output ports of an operator are called locations
**** Summary is the increment made by an internal edge of the operator over the message's timestamp
*** Messages tagged with a timestamp (logical/temporal grouping)
*** Timestamps coordinate the iterations itself of the program and the new incoming input (allows incremental computing)
*** Pointstamps: a pointstamp /(l, t)/ refers to a location /l/ in the dataflow and a timestamp /t/
*** Frontier of a location:
**** Informal idea: it informs each of the operators the timestamp lower bound they may still receive, so they can decide if they have already seen all the data for a certain timestamp
** Worker parallelism: distributed instances of the program (the entire dataflow graph)
[[./workers.png]]
* What this paper is about?
** The questions:
1. How do we coordinate the iterations of the program within the instance itself and the other instances?
2. How do we keep track of the entire system's progress?
3. How do we propagate timestamps between workers and keep the frontiers correctly updated?
4. How do we ensure to always have a consistent result no matter how many workers we use?
** Progress tracking (the solution):
*** Three parts:
1. Local component
2. Distributed component
3. The combination of both
* Progress Tracking (Local)
** Specification of the Timely Dataflow
** Highlights of formalization in Isabelle:
*** Weighted directed graph: vertex are input and outputs, weights are timestamps increments
*** Dataflow constraints: cycles must have a strictly increasing path summary
*** Local propagation:
**** Each location propagates its timestamps to other immediately connected locations
**** Formalized in a state-machine fashion
** The Safety Property
*** We expect the propagation protocol to:
1. eventually informs the new timestamps to all locations and;
2. all implied frontiers converges based on the new timestamps
*** Lets call /worklist/ the set of timestamps of a location that was not propagated yet
*** Then safety is:
**** If a timestamp /t/ is no longer present in any /worklist/, then all frontiers are updated in respect a /t/
* Progress Tracking (Distributed)
** The Clocks Protocol (aka Exchange protocol)
*** Presented by Abadi et al. in TLA+ with the usual state-machine formalization
*** Port TLA+ \rightarrow Isabelle (using co-induction as a trick to encode temporal logic)
*** State-machine
*** Safety: if a pointstamp is vacant in one worker (now), then it is vacant for the global system state (for now and forever)
*** Two problems:
1. Transitions operations can access a global state (the /rec/ multiset)
2. Some restrictions on transition operations are too strong for a real implementation
***** Uprightness: Timestamps can only be added if there is following up removal of a smaller timestamp
** The New Exhanging Protocol
*** Presented in this paper as a solution to both problems
**** Problem 1: split /rec/ into:
***** /cap/ as the set of pointstamps that a worker is capable to send
***** /data/ the set of messages (worker \times pointstamp) that were sent and are in-flight to the receiver workers
***** /rec/ = (\sum /caps c w/) + (map snd (data c))
**** Problem 2:
***** Substitute uprightness:
****** To send positive change of /cap/, the worker must hold positive capability for strictly smaller timestamps
*** Same safety property was proved
* The Combined Protocols
** Combining Distributed and Local
*** Safety: Frontiers reflect timestamps that may arive both locally (dataflow) and across different workers
*** Not proven: termination
* Conclusion and Possible Next Steps
** Conclusion
*** Safety was proved for both protocols and its combination
** Possible next Steps
**** Already mentioned in the paper:
***** Termination of the propagation
***** Extract executable code from the formalization
****** Local propagation already is executable
****** Experimental testing comparing it with the Rust implementation
**** Ideas suggested in the ITP presentation:
***** Consider failure models
**** My own ideas:
***** Consider deployment and scaling scenarios
***** Define correctness and prove it
***** Investigate relations with other models of computation
***** Prove input-output order preservation
